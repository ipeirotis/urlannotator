URLAnnotator architecture proposal
==================================

We will define here possible architectures for this project, with their pros and cons to enable us to choose the best one.


Core components/services:
-------------------------

- *JobPoster* - Place which creates *Job* s with their descriptions, manages accounts, their balances etc.

- *TrainingDataCollector* - component that given description collects matching samples (in this case urls). It will do this by using crowdsourcing platform like oDesk

- *DataValidator* - it is mechanism that takes given url and label that it was assigned and checks whether this label is right. It will be used on data generated by *TrainingDataCollector* and potentially to measure *classifier* performance

- *Classifier* - binary classifier which will decide whether website given by url matches description attached to this *Job*

- *BeatTheMachine* - mechanism for constant validation of classifier with some new data - using crowdsourcing


Service oriented
----------------

We c






Component specification
=======================

Sample
------

Created by *TrainingDataCollector*. It contains:

- url
- text / content of the website
- screen-shot (probably some url address to S3)

Optionally also:

- added_by - Worker
- added_on - date it was added

It is used to generate HIT in validation stage and to generate training sample for *Classifier*


Classifier
----------
Class abstract with methods (sample is of class *Sample*:

- new(description, classes)
- addTrainingSample(sample, class)
- addTrainingSamples([(sample, class)]) default implementation uses addTrainingSample
- classify(sample) -> class
- classify_with_info(sample) -> json? class and probability distribution over classes etc.

Implemented with:

- Google Prediction API
- some simple test classifier? (Orange library?)


What can go wrong:
~~~~~~~~~~~~~~~~~~

- quota exceeded - we throw exception and depending on situation handle it properly. When we are at stage of collecting samples for training we should buffer them. If we are classifying for user some of his samples we will just present to him this information.
- Internal fail: like out of memory, dead service (when using Google Prediction) or just some crash due to some internal bug etc.


Classifier based on Google Prediction API
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

We will have to use Google Cloud Storage.
Good source of information can be found:
https://developers.google.com/prediction/docs/developer-guide
I'm still not sure if we can use long texts as samples...


BeatTheMahine
-------------

It will be designed.



TrainingSamplesCollector
------------------------

This will use Tagasauris.
As input it takes job description and creates proper tasks using Tagasauris.



Useful small elements
----------------------

- exception QuotaLimitExceeded



Smaller components
------------------

*WorkerAction*,

Revenue
~~~~~~~
Defines how much do we pay users for their jobs.

*RevenueDefinition* is mapping from (*WorkerAction*, *result*) into *Money*?
This should be stored in some csv or json file so that it can be configured.


BeatTheMachineRevenueMechanics
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Defines how much revenue will be given to worker for proving given sample. Components:

- *RevenueType* - describes whether we are satisfied with sample provided by user or not. Examples:

 - TP or TN - no error - useless sample for us
 - FP
 - FN
 - low confidence but correct

 etc

-
- RevenueDefinition - mapping from

method *reporterRevenue(classifier_difference ...)*
returns payback or


Notes & TODO's
==============

EventBus Notes
--------------

Known EventListeners registered on all kind of events:

- BusLogger
- BusErrorReporter (to sent errors to Sentry-like service, email etc)


Other Notes
-----------

- Storage for samples given to train classificator?
- Storage for samples given by Workers
- Storage for votes given to samples by Workers
- Storage for samples and their rating in BeatTheMachine
-
